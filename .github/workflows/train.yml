name: train-mlflow

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  train:
    runs-on: self-hosted
    defaults:
      run:
        shell: powershell
    env:
      # Emplacements persistants
      MLFLOW_DB_URI: sqlite:///C:/mlflow-data/tp-mlflow-automation/mlflow.db
      MLFLOW_ARTIFACTS_DIR: C:/mlflow-data/tp-mlflow-automation/artifacts
      # On travaille TOUJOURS avec le port fixe 5000
      MLFLOW_TRACKING_URI: http://127.0.0.1:5000

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Create venv (from Actions Python)
        run: |
          Remove-Item Env:PYTHONHOME, Env:PYTHONPATH -ErrorAction SilentlyContinue
          & "$env:PythonLocation\python.exe" -m venv .venv
          $venv = Join-Path $env:GITHUB_WORKSPACE '.venv\Scripts\python.exe'
          & $venv -c "import sys,ssl; print('PY:', sys.executable); print('SSL OK:', bool(ssl))"
          "VENV_PY=$venv" | Out-File -Append -FilePath $env:GITHUB_ENV

      - name: Install deps (in venv)
        run: |
          $py = $env:VENV_PY
          & $py -m pip install --upgrade pip setuptools wheel
          if (Test-Path requirements.txt) { & $py -m pip install -r requirements.txt }
          & $py -m pip install "mlflow>=2.8,<3" requests pytest

      # ⬇️ Démarre l'UI MLflow sur 5000 et ATTEND qu'elle réponde
      - name: Ensure MLflow UI is running on port 5000 (persist & wait)
        run: |
          $py = $env:VENV_PY

          # Dossiers
          New-Item -ItemType Directory -Force "C:\mlflow-data\tp-mlflow-automation" | Out-Null
          New-Item -ItemType Directory -Force "$env:MLFLOW_ARTIFACTS_DIR" | Out-Null

          # file:/// URI
          $art = ($env:MLFLOW_ARTIFACTS_DIR -replace '\\','/')
          if ($art -notmatch '^file:') { $artUri = "file:///$art" } else { $artUri = $art }

          # Logs dédiés UI
          $out = "mlflow-ui-5000.out"
          $err = "mlflow-ui-5000.err"
          Remove-Item $out, $err -Force -ErrorAction SilentlyContinue

          # Démarre seulement si rien n'écoute déjà sur 5000
          $port = 5000
          $tcp = Get-NetTCPConnection -LocalPort $port -ErrorAction SilentlyContinue
          if (-not $tcp) {
            $args2 = @(
              "-m","mlflow","server",
              "--backend-store-uri",$env:MLFLOW_DB_URI,
              "--serve-artifacts",
              "--artifacts-destination",$artUri,
              "--host","127.0.0.1","--port",$port
            )
            Start-Process -FilePath $py -ArgumentList $args2 `
              -RedirectStandardOutput $out -RedirectStandardError $err -WindowStyle Hidden
            Start-Sleep -Seconds 2
          } else {
            Write-Host "MLflow UI already listening on port $port"
          }

          # Attendre jusqu'à 30s que l'UI réponde
          $ok = $false
          for ($i = 0; $i -lt 15; $i++) {
            try {
              Invoke-WebRequest -UseBasicParsing -Uri "http://127.0.0.1:$port" -TimeoutSec 2 | Out-Null
              $ok = $true; break
            } catch { Start-Sleep -Seconds 2 }
          }
          if (-not $ok) {
            Write-Host "=== mlflow-ui-5000.err (tail) ==="
            Get-Content -LiteralPath $err -Tail 200 -ErrorAction SilentlyContinue
            Write-Host "=== mlflow-ui-5000.out (tail) ==="
            Get-Content -LiteralPath $out -Tail 200 -ErrorAction SilentlyContinue
            throw "MLflow UI did not become ready on 127.0.0.1:$port"
          } else {
            Write-Host "MLflow UI is ready on http://127.0.0.1:$port"
          }

      # ⬇️ CI : smoke + tests + train + show (on NE redémarre plus de serveur)
      - name: CI steps (smoke, tests, train, show)
        run: |
          $py = $env:VENV_PY

          # Smoke
          @(
            'import os, requests',
            "url = os.environ.get('MLFLOW_TRACKING_URI','http://127.0.0.1:5000')",
            'r = requests.get(url, timeout=5)',
            'print("MLflow UI reachable:", r.status_code)'
          ) | Set-Content -LiteralPath smoke.py -Encoding UTF8
          & $py smoke.py

          # Tests
          & $py -m pytest -q

          # Train (pas de contrainte d’accuracy)
          & $py src\train.py --experiment-name "ci-experiment" --registered-model-name "IrisClassifier" --C 1.0 --max-iter 200 --seed 42 --min-accuracy 0.0

          # Show runs
          @(
            'import os, mlflow',
            'from mlflow.tracking import MlflowClient',
            "print('Tracking URI:', os.getenv('MLFLOW_TRACKING_URI'))",
            'c = MlflowClient()',
            'exps = {e.name: e.experiment_id for e in c.search_experiments()}',
            "eid = exps.get('ci-experiment')",
            'if eid:',
            "    runs = c.search_runs([eid], order_by=['metrics.accuracy DESC'], max_results=5)",
            '    for r in runs:',
            "        print(r.info.run_id, r.data.metrics.get('accuracy'))",
            'else:',
            '    print("Experiment ''ci-experiment'' not found")'
          ) | Set-Content -LiteralPath show_runs.py -Encoding UTF8
          & $py show_runs.py

      # ⬇️ Ouvre le navigateur uniquement si l'UI est répondante
      - name: Open MLflow UI in browser
        run: |
          try {
            Invoke-WebRequest -UseBasicParsing -Uri "http://127.0.0.1:5000" -TimeoutSec 2 | Out-Null
            Start-Process "cmd.exe" "/c start http://127.0.0.1:5000"
          } catch {
            Write-Host "UI not reachable now; open http://127.0.0.1:5000 manually."
          }

















